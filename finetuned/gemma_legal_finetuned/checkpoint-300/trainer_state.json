{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.17069701280227595,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002844950213371266,
      "grad_norm": 0.4949305057525635,
      "learning_rate": 0.00019943084803642573,
      "loss": 2.2738,
      "step": 5
    },
    {
      "epoch": 0.005689900426742532,
      "grad_norm": 0.5478770136833191,
      "learning_rate": 0.00019886169607285145,
      "loss": 2.1523,
      "step": 10
    },
    {
      "epoch": 0.008534850640113799,
      "grad_norm": 0.4918110966682434,
      "learning_rate": 0.00019829254410927717,
      "loss": 2.0182,
      "step": 15
    },
    {
      "epoch": 0.011379800853485065,
      "grad_norm": 0.46867555379867554,
      "learning_rate": 0.0001977233921457029,
      "loss": 2.0836,
      "step": 20
    },
    {
      "epoch": 0.01422475106685633,
      "grad_norm": 0.4838064908981323,
      "learning_rate": 0.00019715424018212864,
      "loss": 1.8437,
      "step": 25
    },
    {
      "epoch": 0.017069701280227598,
      "grad_norm": 0.5012277364730835,
      "learning_rate": 0.00019658508821855436,
      "loss": 1.8759,
      "step": 30
    },
    {
      "epoch": 0.01991465149359886,
      "grad_norm": 0.44116437435150146,
      "learning_rate": 0.0001960159362549801,
      "loss": 1.9221,
      "step": 35
    },
    {
      "epoch": 0.02275960170697013,
      "grad_norm": 0.46326640248298645,
      "learning_rate": 0.00019544678429140583,
      "loss": 1.8934,
      "step": 40
    },
    {
      "epoch": 0.025604551920341393,
      "grad_norm": 0.4289257824420929,
      "learning_rate": 0.00019487763232783155,
      "loss": 1.8505,
      "step": 45
    },
    {
      "epoch": 0.02844950213371266,
      "grad_norm": 0.46900564432144165,
      "learning_rate": 0.00019430848036425727,
      "loss": 1.9045,
      "step": 50
    },
    {
      "epoch": 0.031294452347083924,
      "grad_norm": 0.5247617363929749,
      "learning_rate": 0.00019373932840068299,
      "loss": 1.8131,
      "step": 55
    },
    {
      "epoch": 0.034139402560455195,
      "grad_norm": 0.4680875837802887,
      "learning_rate": 0.0001931701764371087,
      "loss": 1.8481,
      "step": 60
    },
    {
      "epoch": 0.03698435277382646,
      "grad_norm": 0.523281455039978,
      "learning_rate": 0.00019260102447353445,
      "loss": 1.9826,
      "step": 65
    },
    {
      "epoch": 0.03982930298719772,
      "grad_norm": 0.4950197637081146,
      "learning_rate": 0.00019203187250996017,
      "loss": 1.8674,
      "step": 70
    },
    {
      "epoch": 0.04267425320056899,
      "grad_norm": 0.5106218457221985,
      "learning_rate": 0.0001914627205463859,
      "loss": 1.8541,
      "step": 75
    },
    {
      "epoch": 0.04551920341394026,
      "grad_norm": 0.46364477276802063,
      "learning_rate": 0.00019089356858281161,
      "loss": 1.8454,
      "step": 80
    },
    {
      "epoch": 0.04836415362731152,
      "grad_norm": 0.5279164910316467,
      "learning_rate": 0.00019032441661923733,
      "loss": 1.7972,
      "step": 85
    },
    {
      "epoch": 0.051209103840682786,
      "grad_norm": 0.48782220482826233,
      "learning_rate": 0.00018975526465566305,
      "loss": 1.8047,
      "step": 90
    },
    {
      "epoch": 0.05405405405405406,
      "grad_norm": 0.5064043402671814,
      "learning_rate": 0.0001891861126920888,
      "loss": 1.7437,
      "step": 95
    },
    {
      "epoch": 0.05689900426742532,
      "grad_norm": 0.5325073003768921,
      "learning_rate": 0.00018861696072851452,
      "loss": 1.8588,
      "step": 100
    },
    {
      "epoch": 0.059743954480796585,
      "grad_norm": 0.4949420392513275,
      "learning_rate": 0.00018804780876494027,
      "loss": 1.9295,
      "step": 105
    },
    {
      "epoch": 0.06258890469416785,
      "grad_norm": 0.5514007806777954,
      "learning_rate": 0.000187478656801366,
      "loss": 1.8105,
      "step": 110
    },
    {
      "epoch": 0.06543385490753911,
      "grad_norm": 0.561600387096405,
      "learning_rate": 0.0001869095048377917,
      "loss": 1.8116,
      "step": 115
    },
    {
      "epoch": 0.06827880512091039,
      "grad_norm": 0.5257200598716736,
      "learning_rate": 0.00018634035287421743,
      "loss": 1.852,
      "step": 120
    },
    {
      "epoch": 0.07112375533428165,
      "grad_norm": 0.4855252802371979,
      "learning_rate": 0.00018577120091064315,
      "loss": 1.8639,
      "step": 125
    },
    {
      "epoch": 0.07396870554765292,
      "grad_norm": 0.5099745988845825,
      "learning_rate": 0.00018520204894706887,
      "loss": 1.7894,
      "step": 130
    },
    {
      "epoch": 0.07681365576102418,
      "grad_norm": 0.4951542317867279,
      "learning_rate": 0.0001846328969834946,
      "loss": 1.7587,
      "step": 135
    },
    {
      "epoch": 0.07965860597439545,
      "grad_norm": 0.5255674719810486,
      "learning_rate": 0.0001840637450199203,
      "loss": 1.9911,
      "step": 140
    },
    {
      "epoch": 0.08250355618776671,
      "grad_norm": 0.4962505102157593,
      "learning_rate": 0.00018349459305634603,
      "loss": 1.7364,
      "step": 145
    },
    {
      "epoch": 0.08534850640113797,
      "grad_norm": 0.49747973680496216,
      "learning_rate": 0.00018292544109277178,
      "loss": 1.8365,
      "step": 150
    },
    {
      "epoch": 0.08819345661450925,
      "grad_norm": 0.5000907182693481,
      "learning_rate": 0.0001823562891291975,
      "loss": 1.7884,
      "step": 155
    },
    {
      "epoch": 0.09103840682788052,
      "grad_norm": 0.5320129990577698,
      "learning_rate": 0.00018178713716562325,
      "loss": 1.8548,
      "step": 160
    },
    {
      "epoch": 0.09388335704125178,
      "grad_norm": 0.5494191646575928,
      "learning_rate": 0.00018121798520204897,
      "loss": 1.8061,
      "step": 165
    },
    {
      "epoch": 0.09672830725462304,
      "grad_norm": 0.5762655138969421,
      "learning_rate": 0.0001806488332384747,
      "loss": 1.8744,
      "step": 170
    },
    {
      "epoch": 0.09957325746799431,
      "grad_norm": 0.5443115830421448,
      "learning_rate": 0.0001800796812749004,
      "loss": 1.9422,
      "step": 175
    },
    {
      "epoch": 0.10241820768136557,
      "grad_norm": 0.5426173210144043,
      "learning_rate": 0.00017951052931132613,
      "loss": 1.9794,
      "step": 180
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 0.5198436379432678,
      "learning_rate": 0.00017894137734775185,
      "loss": 1.8975,
      "step": 185
    },
    {
      "epoch": 0.10810810810810811,
      "grad_norm": 0.5192174911499023,
      "learning_rate": 0.0001783722253841776,
      "loss": 1.9407,
      "step": 190
    },
    {
      "epoch": 0.11095305832147938,
      "grad_norm": 0.5123754739761353,
      "learning_rate": 0.00017780307342060332,
      "loss": 1.7721,
      "step": 195
    },
    {
      "epoch": 0.11379800853485064,
      "grad_norm": 0.5444467067718506,
      "learning_rate": 0.00017723392145702904,
      "loss": 1.7668,
      "step": 200
    },
    {
      "epoch": 0.1166429587482219,
      "grad_norm": 0.48558250069618225,
      "learning_rate": 0.00017666476949345476,
      "loss": 1.8502,
      "step": 205
    },
    {
      "epoch": 0.11948790896159317,
      "grad_norm": 0.5235543847084045,
      "learning_rate": 0.00017609561752988048,
      "loss": 1.7303,
      "step": 210
    },
    {
      "epoch": 0.12233285917496443,
      "grad_norm": 0.5079710483551025,
      "learning_rate": 0.0001755264655663062,
      "loss": 1.6375,
      "step": 215
    },
    {
      "epoch": 0.1251778093883357,
      "grad_norm": 0.5100827813148499,
      "learning_rate": 0.00017495731360273194,
      "loss": 1.7996,
      "step": 220
    },
    {
      "epoch": 0.12802275960170698,
      "grad_norm": 0.524852991104126,
      "learning_rate": 0.00017438816163915766,
      "loss": 1.7877,
      "step": 225
    },
    {
      "epoch": 0.13086770981507823,
      "grad_norm": 0.5219963788986206,
      "learning_rate": 0.0001738190096755834,
      "loss": 1.8222,
      "step": 230
    },
    {
      "epoch": 0.1337126600284495,
      "grad_norm": 0.54615318775177,
      "learning_rate": 0.00017324985771200913,
      "loss": 1.8048,
      "step": 235
    },
    {
      "epoch": 0.13655761024182078,
      "grad_norm": 0.4962216913700104,
      "learning_rate": 0.00017268070574843485,
      "loss": 1.7844,
      "step": 240
    },
    {
      "epoch": 0.13940256045519203,
      "grad_norm": 0.5254645943641663,
      "learning_rate": 0.00017211155378486057,
      "loss": 1.806,
      "step": 245
    },
    {
      "epoch": 0.1422475106685633,
      "grad_norm": 0.5344192981719971,
      "learning_rate": 0.0001715424018212863,
      "loss": 1.7977,
      "step": 250
    },
    {
      "epoch": 0.14509246088193456,
      "grad_norm": 0.5260816216468811,
      "learning_rate": 0.000170973249857712,
      "loss": 1.7991,
      "step": 255
    },
    {
      "epoch": 0.14793741109530584,
      "grad_norm": 0.536462664604187,
      "learning_rate": 0.00017040409789413773,
      "loss": 1.8164,
      "step": 260
    },
    {
      "epoch": 0.1507823613086771,
      "grad_norm": 0.534024715423584,
      "learning_rate": 0.00016983494593056345,
      "loss": 1.8092,
      "step": 265
    },
    {
      "epoch": 0.15362731152204837,
      "grad_norm": 0.5141861438751221,
      "learning_rate": 0.00016926579396698917,
      "loss": 1.8453,
      "step": 270
    },
    {
      "epoch": 0.15647226173541964,
      "grad_norm": 0.5123191475868225,
      "learning_rate": 0.00016869664200341492,
      "loss": 1.8227,
      "step": 275
    },
    {
      "epoch": 0.1593172119487909,
      "grad_norm": 0.5313526391983032,
      "learning_rate": 0.00016812749003984064,
      "loss": 1.7419,
      "step": 280
    },
    {
      "epoch": 0.16216216216216217,
      "grad_norm": 0.5069981813430786,
      "learning_rate": 0.0001675583380762664,
      "loss": 1.8631,
      "step": 285
    },
    {
      "epoch": 0.16500711237553342,
      "grad_norm": 0.5520071387290955,
      "learning_rate": 0.0001669891861126921,
      "loss": 1.8749,
      "step": 290
    },
    {
      "epoch": 0.1678520625889047,
      "grad_norm": 0.5548297166824341,
      "learning_rate": 0.00016642003414911783,
      "loss": 1.8134,
      "step": 295
    },
    {
      "epoch": 0.17069701280227595,
      "grad_norm": 0.5602995157241821,
      "learning_rate": 0.00016585088218554355,
      "loss": 1.8562,
      "step": 300
    }
  ],
  "logging_steps": 5,
  "max_steps": 1757,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4918312709282816e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
