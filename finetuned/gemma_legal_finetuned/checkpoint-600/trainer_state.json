{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3413940256045519,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002844950213371266,
      "grad_norm": 0.4949305057525635,
      "learning_rate": 0.00019943084803642573,
      "loss": 2.2738,
      "step": 5
    },
    {
      "epoch": 0.005689900426742532,
      "grad_norm": 0.5478770136833191,
      "learning_rate": 0.00019886169607285145,
      "loss": 2.1523,
      "step": 10
    },
    {
      "epoch": 0.008534850640113799,
      "grad_norm": 0.4918110966682434,
      "learning_rate": 0.00019829254410927717,
      "loss": 2.0182,
      "step": 15
    },
    {
      "epoch": 0.011379800853485065,
      "grad_norm": 0.46867555379867554,
      "learning_rate": 0.0001977233921457029,
      "loss": 2.0836,
      "step": 20
    },
    {
      "epoch": 0.01422475106685633,
      "grad_norm": 0.4838064908981323,
      "learning_rate": 0.00019715424018212864,
      "loss": 1.8437,
      "step": 25
    },
    {
      "epoch": 0.017069701280227598,
      "grad_norm": 0.5012277364730835,
      "learning_rate": 0.00019658508821855436,
      "loss": 1.8759,
      "step": 30
    },
    {
      "epoch": 0.01991465149359886,
      "grad_norm": 0.44116437435150146,
      "learning_rate": 0.0001960159362549801,
      "loss": 1.9221,
      "step": 35
    },
    {
      "epoch": 0.02275960170697013,
      "grad_norm": 0.46326640248298645,
      "learning_rate": 0.00019544678429140583,
      "loss": 1.8934,
      "step": 40
    },
    {
      "epoch": 0.025604551920341393,
      "grad_norm": 0.4289257824420929,
      "learning_rate": 0.00019487763232783155,
      "loss": 1.8505,
      "step": 45
    },
    {
      "epoch": 0.02844950213371266,
      "grad_norm": 0.46900564432144165,
      "learning_rate": 0.00019430848036425727,
      "loss": 1.9045,
      "step": 50
    },
    {
      "epoch": 0.031294452347083924,
      "grad_norm": 0.5247617363929749,
      "learning_rate": 0.00019373932840068299,
      "loss": 1.8131,
      "step": 55
    },
    {
      "epoch": 0.034139402560455195,
      "grad_norm": 0.4680875837802887,
      "learning_rate": 0.0001931701764371087,
      "loss": 1.8481,
      "step": 60
    },
    {
      "epoch": 0.03698435277382646,
      "grad_norm": 0.523281455039978,
      "learning_rate": 0.00019260102447353445,
      "loss": 1.9826,
      "step": 65
    },
    {
      "epoch": 0.03982930298719772,
      "grad_norm": 0.4950197637081146,
      "learning_rate": 0.00019203187250996017,
      "loss": 1.8674,
      "step": 70
    },
    {
      "epoch": 0.04267425320056899,
      "grad_norm": 0.5106218457221985,
      "learning_rate": 0.0001914627205463859,
      "loss": 1.8541,
      "step": 75
    },
    {
      "epoch": 0.04551920341394026,
      "grad_norm": 0.46364477276802063,
      "learning_rate": 0.00019089356858281161,
      "loss": 1.8454,
      "step": 80
    },
    {
      "epoch": 0.04836415362731152,
      "grad_norm": 0.5279164910316467,
      "learning_rate": 0.00019032441661923733,
      "loss": 1.7972,
      "step": 85
    },
    {
      "epoch": 0.051209103840682786,
      "grad_norm": 0.48782220482826233,
      "learning_rate": 0.00018975526465566305,
      "loss": 1.8047,
      "step": 90
    },
    {
      "epoch": 0.05405405405405406,
      "grad_norm": 0.5064043402671814,
      "learning_rate": 0.0001891861126920888,
      "loss": 1.7437,
      "step": 95
    },
    {
      "epoch": 0.05689900426742532,
      "grad_norm": 0.5325073003768921,
      "learning_rate": 0.00018861696072851452,
      "loss": 1.8588,
      "step": 100
    },
    {
      "epoch": 0.059743954480796585,
      "grad_norm": 0.4949420392513275,
      "learning_rate": 0.00018804780876494027,
      "loss": 1.9295,
      "step": 105
    },
    {
      "epoch": 0.06258890469416785,
      "grad_norm": 0.5514007806777954,
      "learning_rate": 0.000187478656801366,
      "loss": 1.8105,
      "step": 110
    },
    {
      "epoch": 0.06543385490753911,
      "grad_norm": 0.561600387096405,
      "learning_rate": 0.0001869095048377917,
      "loss": 1.8116,
      "step": 115
    },
    {
      "epoch": 0.06827880512091039,
      "grad_norm": 0.5257200598716736,
      "learning_rate": 0.00018634035287421743,
      "loss": 1.852,
      "step": 120
    },
    {
      "epoch": 0.07112375533428165,
      "grad_norm": 0.4855252802371979,
      "learning_rate": 0.00018577120091064315,
      "loss": 1.8639,
      "step": 125
    },
    {
      "epoch": 0.07396870554765292,
      "grad_norm": 0.5099745988845825,
      "learning_rate": 0.00018520204894706887,
      "loss": 1.7894,
      "step": 130
    },
    {
      "epoch": 0.07681365576102418,
      "grad_norm": 0.4951542317867279,
      "learning_rate": 0.0001846328969834946,
      "loss": 1.7587,
      "step": 135
    },
    {
      "epoch": 0.07965860597439545,
      "grad_norm": 0.5255674719810486,
      "learning_rate": 0.0001840637450199203,
      "loss": 1.9911,
      "step": 140
    },
    {
      "epoch": 0.08250355618776671,
      "grad_norm": 0.4962505102157593,
      "learning_rate": 0.00018349459305634603,
      "loss": 1.7364,
      "step": 145
    },
    {
      "epoch": 0.08534850640113797,
      "grad_norm": 0.49747973680496216,
      "learning_rate": 0.00018292544109277178,
      "loss": 1.8365,
      "step": 150
    },
    {
      "epoch": 0.08819345661450925,
      "grad_norm": 0.5000907182693481,
      "learning_rate": 0.0001823562891291975,
      "loss": 1.7884,
      "step": 155
    },
    {
      "epoch": 0.09103840682788052,
      "grad_norm": 0.5320129990577698,
      "learning_rate": 0.00018178713716562325,
      "loss": 1.8548,
      "step": 160
    },
    {
      "epoch": 0.09388335704125178,
      "grad_norm": 0.5494191646575928,
      "learning_rate": 0.00018121798520204897,
      "loss": 1.8061,
      "step": 165
    },
    {
      "epoch": 0.09672830725462304,
      "grad_norm": 0.5762655138969421,
      "learning_rate": 0.0001806488332384747,
      "loss": 1.8744,
      "step": 170
    },
    {
      "epoch": 0.09957325746799431,
      "grad_norm": 0.5443115830421448,
      "learning_rate": 0.0001800796812749004,
      "loss": 1.9422,
      "step": 175
    },
    {
      "epoch": 0.10241820768136557,
      "grad_norm": 0.5426173210144043,
      "learning_rate": 0.00017951052931132613,
      "loss": 1.9794,
      "step": 180
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 0.5198436379432678,
      "learning_rate": 0.00017894137734775185,
      "loss": 1.8975,
      "step": 185
    },
    {
      "epoch": 0.10810810810810811,
      "grad_norm": 0.5192174911499023,
      "learning_rate": 0.0001783722253841776,
      "loss": 1.9407,
      "step": 190
    },
    {
      "epoch": 0.11095305832147938,
      "grad_norm": 0.5123754739761353,
      "learning_rate": 0.00017780307342060332,
      "loss": 1.7721,
      "step": 195
    },
    {
      "epoch": 0.11379800853485064,
      "grad_norm": 0.5444467067718506,
      "learning_rate": 0.00017723392145702904,
      "loss": 1.7668,
      "step": 200
    },
    {
      "epoch": 0.1166429587482219,
      "grad_norm": 0.48558250069618225,
      "learning_rate": 0.00017666476949345476,
      "loss": 1.8502,
      "step": 205
    },
    {
      "epoch": 0.11948790896159317,
      "grad_norm": 0.5235543847084045,
      "learning_rate": 0.00017609561752988048,
      "loss": 1.7303,
      "step": 210
    },
    {
      "epoch": 0.12233285917496443,
      "grad_norm": 0.5079710483551025,
      "learning_rate": 0.0001755264655663062,
      "loss": 1.6375,
      "step": 215
    },
    {
      "epoch": 0.1251778093883357,
      "grad_norm": 0.5100827813148499,
      "learning_rate": 0.00017495731360273194,
      "loss": 1.7996,
      "step": 220
    },
    {
      "epoch": 0.12802275960170698,
      "grad_norm": 0.524852991104126,
      "learning_rate": 0.00017438816163915766,
      "loss": 1.7877,
      "step": 225
    },
    {
      "epoch": 0.13086770981507823,
      "grad_norm": 0.5219963788986206,
      "learning_rate": 0.0001738190096755834,
      "loss": 1.8222,
      "step": 230
    },
    {
      "epoch": 0.1337126600284495,
      "grad_norm": 0.54615318775177,
      "learning_rate": 0.00017324985771200913,
      "loss": 1.8048,
      "step": 235
    },
    {
      "epoch": 0.13655761024182078,
      "grad_norm": 0.4962216913700104,
      "learning_rate": 0.00017268070574843485,
      "loss": 1.7844,
      "step": 240
    },
    {
      "epoch": 0.13940256045519203,
      "grad_norm": 0.5254645943641663,
      "learning_rate": 0.00017211155378486057,
      "loss": 1.806,
      "step": 245
    },
    {
      "epoch": 0.1422475106685633,
      "grad_norm": 0.5344192981719971,
      "learning_rate": 0.0001715424018212863,
      "loss": 1.7977,
      "step": 250
    },
    {
      "epoch": 0.14509246088193456,
      "grad_norm": 0.5260816216468811,
      "learning_rate": 0.000170973249857712,
      "loss": 1.7991,
      "step": 255
    },
    {
      "epoch": 0.14793741109530584,
      "grad_norm": 0.536462664604187,
      "learning_rate": 0.00017040409789413773,
      "loss": 1.8164,
      "step": 260
    },
    {
      "epoch": 0.1507823613086771,
      "grad_norm": 0.534024715423584,
      "learning_rate": 0.00016983494593056345,
      "loss": 1.8092,
      "step": 265
    },
    {
      "epoch": 0.15362731152204837,
      "grad_norm": 0.5141861438751221,
      "learning_rate": 0.00016926579396698917,
      "loss": 1.8453,
      "step": 270
    },
    {
      "epoch": 0.15647226173541964,
      "grad_norm": 0.5123191475868225,
      "learning_rate": 0.00016869664200341492,
      "loss": 1.8227,
      "step": 275
    },
    {
      "epoch": 0.1593172119487909,
      "grad_norm": 0.5313526391983032,
      "learning_rate": 0.00016812749003984064,
      "loss": 1.7419,
      "step": 280
    },
    {
      "epoch": 0.16216216216216217,
      "grad_norm": 0.5069981813430786,
      "learning_rate": 0.0001675583380762664,
      "loss": 1.8631,
      "step": 285
    },
    {
      "epoch": 0.16500711237553342,
      "grad_norm": 0.5520071387290955,
      "learning_rate": 0.0001669891861126921,
      "loss": 1.8749,
      "step": 290
    },
    {
      "epoch": 0.1678520625889047,
      "grad_norm": 0.5548297166824341,
      "learning_rate": 0.00016642003414911783,
      "loss": 1.8134,
      "step": 295
    },
    {
      "epoch": 0.17069701280227595,
      "grad_norm": 0.5602995157241821,
      "learning_rate": 0.00016585088218554355,
      "loss": 1.8562,
      "step": 300
    },
    {
      "epoch": 0.17354196301564723,
      "grad_norm": 0.584997832775116,
      "learning_rate": 0.00016528173022196927,
      "loss": 1.6884,
      "step": 305
    },
    {
      "epoch": 0.1763869132290185,
      "grad_norm": 0.5142406821250916,
      "learning_rate": 0.000164712578258395,
      "loss": 1.7798,
      "step": 310
    },
    {
      "epoch": 0.17923186344238975,
      "grad_norm": 0.542140543460846,
      "learning_rate": 0.00016414342629482074,
      "loss": 1.8115,
      "step": 315
    },
    {
      "epoch": 0.18207681365576103,
      "grad_norm": 0.5546067953109741,
      "learning_rate": 0.00016357427433124646,
      "loss": 1.8028,
      "step": 320
    },
    {
      "epoch": 0.18492176386913228,
      "grad_norm": 0.5099424719810486,
      "learning_rate": 0.00016300512236767218,
      "loss": 1.7713,
      "step": 325
    },
    {
      "epoch": 0.18776671408250356,
      "grad_norm": 0.5469363927841187,
      "learning_rate": 0.0001624359704040979,
      "loss": 1.7708,
      "step": 330
    },
    {
      "epoch": 0.1906116642958748,
      "grad_norm": 0.5607678890228271,
      "learning_rate": 0.00016186681844052362,
      "loss": 1.854,
      "step": 335
    },
    {
      "epoch": 0.1934566145092461,
      "grad_norm": 0.550093412399292,
      "learning_rate": 0.00016129766647694934,
      "loss": 1.7278,
      "step": 340
    },
    {
      "epoch": 0.19630156472261737,
      "grad_norm": 0.6458361744880676,
      "learning_rate": 0.00016072851451337508,
      "loss": 1.8848,
      "step": 345
    },
    {
      "epoch": 0.19914651493598862,
      "grad_norm": 0.5263909101486206,
      "learning_rate": 0.0001601593625498008,
      "loss": 1.7014,
      "step": 350
    },
    {
      "epoch": 0.2019914651493599,
      "grad_norm": 0.5069615244865417,
      "learning_rate": 0.00015959021058622655,
      "loss": 1.7338,
      "step": 355
    },
    {
      "epoch": 0.20483641536273114,
      "grad_norm": 0.5174620151519775,
      "learning_rate": 0.00015902105862265227,
      "loss": 1.711,
      "step": 360
    },
    {
      "epoch": 0.20768136557610242,
      "grad_norm": 0.536195695400238,
      "learning_rate": 0.000158451906659078,
      "loss": 1.8283,
      "step": 365
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.5349156856536865,
      "learning_rate": 0.0001578827546955037,
      "loss": 1.8303,
      "step": 370
    },
    {
      "epoch": 0.21337126600284495,
      "grad_norm": 0.5570517778396606,
      "learning_rate": 0.00015731360273192943,
      "loss": 1.6737,
      "step": 375
    },
    {
      "epoch": 0.21621621621621623,
      "grad_norm": 0.5562851428985596,
      "learning_rate": 0.00015674445076835515,
      "loss": 1.7031,
      "step": 380
    },
    {
      "epoch": 0.21906116642958748,
      "grad_norm": 0.5085716843605042,
      "learning_rate": 0.00015617529880478087,
      "loss": 1.7839,
      "step": 385
    },
    {
      "epoch": 0.22190611664295876,
      "grad_norm": 0.5509480834007263,
      "learning_rate": 0.0001556061468412066,
      "loss": 1.8322,
      "step": 390
    },
    {
      "epoch": 0.22475106685633,
      "grad_norm": 0.552862286567688,
      "learning_rate": 0.00015503699487763231,
      "loss": 1.8205,
      "step": 395
    },
    {
      "epoch": 0.22759601706970128,
      "grad_norm": 0.5689870119094849,
      "learning_rate": 0.00015446784291405806,
      "loss": 1.8252,
      "step": 400
    },
    {
      "epoch": 0.23044096728307253,
      "grad_norm": 0.5379787683486938,
      "learning_rate": 0.00015389869095048378,
      "loss": 1.7698,
      "step": 405
    },
    {
      "epoch": 0.2332859174964438,
      "grad_norm": 0.5686361193656921,
      "learning_rate": 0.00015332953898690953,
      "loss": 1.81,
      "step": 410
    },
    {
      "epoch": 0.2361308677098151,
      "grad_norm": 0.5446853041648865,
      "learning_rate": 0.00015276038702333525,
      "loss": 1.741,
      "step": 415
    },
    {
      "epoch": 0.23897581792318634,
      "grad_norm": 0.549289882183075,
      "learning_rate": 0.00015219123505976097,
      "loss": 1.7816,
      "step": 420
    },
    {
      "epoch": 0.24182076813655762,
      "grad_norm": 0.5685895085334778,
      "learning_rate": 0.0001516220830961867,
      "loss": 1.7425,
      "step": 425
    },
    {
      "epoch": 0.24466571834992887,
      "grad_norm": 0.5328943729400635,
      "learning_rate": 0.0001510529311326124,
      "loss": 1.7754,
      "step": 430
    },
    {
      "epoch": 0.24751066856330015,
      "grad_norm": 0.5207207202911377,
      "learning_rate": 0.00015048377916903813,
      "loss": 1.7066,
      "step": 435
    },
    {
      "epoch": 0.2503556187766714,
      "grad_norm": 0.5533854961395264,
      "learning_rate": 0.00014991462720546388,
      "loss": 1.8044,
      "step": 440
    },
    {
      "epoch": 0.2532005689900427,
      "grad_norm": 0.5449127554893494,
      "learning_rate": 0.0001493454752418896,
      "loss": 1.7322,
      "step": 445
    },
    {
      "epoch": 0.25604551920341395,
      "grad_norm": 0.5602892637252808,
      "learning_rate": 0.00014877632327831532,
      "loss": 1.8496,
      "step": 450
    },
    {
      "epoch": 0.25889046941678523,
      "grad_norm": 0.6014001965522766,
      "learning_rate": 0.00014820717131474104,
      "loss": 1.7352,
      "step": 455
    },
    {
      "epoch": 0.26173541963015645,
      "grad_norm": 0.5059030652046204,
      "learning_rate": 0.00014763801935116676,
      "loss": 1.7903,
      "step": 460
    },
    {
      "epoch": 0.26458036984352773,
      "grad_norm": 0.5593153834342957,
      "learning_rate": 0.00014706886738759248,
      "loss": 1.8549,
      "step": 465
    },
    {
      "epoch": 0.267425320056899,
      "grad_norm": 0.5455724000930786,
      "learning_rate": 0.00014649971542401823,
      "loss": 1.8233,
      "step": 470
    },
    {
      "epoch": 0.2702702702702703,
      "grad_norm": 0.5374266505241394,
      "learning_rate": 0.00014593056346044395,
      "loss": 1.7071,
      "step": 475
    },
    {
      "epoch": 0.27311522048364156,
      "grad_norm": 0.5489568114280701,
      "learning_rate": 0.0001453614114968697,
      "loss": 1.7843,
      "step": 480
    },
    {
      "epoch": 0.2759601706970128,
      "grad_norm": 0.5015942454338074,
      "learning_rate": 0.00014479225953329541,
      "loss": 1.8701,
      "step": 485
    },
    {
      "epoch": 0.27880512091038406,
      "grad_norm": 0.5308811068534851,
      "learning_rate": 0.00014422310756972113,
      "loss": 1.8204,
      "step": 490
    },
    {
      "epoch": 0.28165007112375534,
      "grad_norm": 0.5483800768852234,
      "learning_rate": 0.00014365395560614685,
      "loss": 1.7381,
      "step": 495
    },
    {
      "epoch": 0.2844950213371266,
      "grad_norm": 0.541336715221405,
      "learning_rate": 0.00014308480364257257,
      "loss": 1.7185,
      "step": 500
    },
    {
      "epoch": 0.28733997155049784,
      "grad_norm": 0.56029212474823,
      "learning_rate": 0.0001425156516789983,
      "loss": 1.7201,
      "step": 505
    },
    {
      "epoch": 0.2901849217638691,
      "grad_norm": 0.5436985492706299,
      "learning_rate": 0.00014194649971542401,
      "loss": 1.8067,
      "step": 510
    },
    {
      "epoch": 0.2930298719772404,
      "grad_norm": 0.5450965762138367,
      "learning_rate": 0.00014137734775184974,
      "loss": 1.8599,
      "step": 515
    },
    {
      "epoch": 0.2958748221906117,
      "grad_norm": 0.5704220533370972,
      "learning_rate": 0.00014080819578827546,
      "loss": 1.7425,
      "step": 520
    },
    {
      "epoch": 0.29871977240398295,
      "grad_norm": 0.5314556360244751,
      "learning_rate": 0.0001402390438247012,
      "loss": 1.779,
      "step": 525
    },
    {
      "epoch": 0.3015647226173542,
      "grad_norm": 0.5982683897018433,
      "learning_rate": 0.00013966989186112692,
      "loss": 1.8211,
      "step": 530
    },
    {
      "epoch": 0.30440967283072545,
      "grad_norm": 0.5527154207229614,
      "learning_rate": 0.00013910073989755264,
      "loss": 1.7719,
      "step": 535
    },
    {
      "epoch": 0.30725462304409673,
      "grad_norm": 0.5959969162940979,
      "learning_rate": 0.0001385315879339784,
      "loss": 1.8675,
      "step": 540
    },
    {
      "epoch": 0.310099573257468,
      "grad_norm": 0.5495197176933289,
      "learning_rate": 0.0001379624359704041,
      "loss": 1.7607,
      "step": 545
    },
    {
      "epoch": 0.3129445234708393,
      "grad_norm": 0.5293635129928589,
      "learning_rate": 0.00013739328400682983,
      "loss": 1.664,
      "step": 550
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 0.5742693543434143,
      "learning_rate": 0.00013682413204325555,
      "loss": 1.7203,
      "step": 555
    },
    {
      "epoch": 0.3186344238975818,
      "grad_norm": 0.5422243475914001,
      "learning_rate": 0.00013625498007968127,
      "loss": 1.7767,
      "step": 560
    },
    {
      "epoch": 0.32147937411095306,
      "grad_norm": 0.5649269223213196,
      "learning_rate": 0.00013568582811610702,
      "loss": 1.8364,
      "step": 565
    },
    {
      "epoch": 0.32432432432432434,
      "grad_norm": 0.5209592580795288,
      "learning_rate": 0.00013511667615253274,
      "loss": 1.7459,
      "step": 570
    },
    {
      "epoch": 0.32716927453769556,
      "grad_norm": 0.5393198132514954,
      "learning_rate": 0.00013454752418895846,
      "loss": 1.7314,
      "step": 575
    },
    {
      "epoch": 0.33001422475106684,
      "grad_norm": 0.5036423802375793,
      "learning_rate": 0.00013397837222538418,
      "loss": 1.7298,
      "step": 580
    },
    {
      "epoch": 0.3328591749644381,
      "grad_norm": 0.5882377028465271,
      "learning_rate": 0.0001334092202618099,
      "loss": 1.7044,
      "step": 585
    },
    {
      "epoch": 0.3357041251778094,
      "grad_norm": 0.5572733879089355,
      "learning_rate": 0.00013284006829823562,
      "loss": 1.7219,
      "step": 590
    },
    {
      "epoch": 0.3385490753911807,
      "grad_norm": 0.5847784876823425,
      "learning_rate": 0.00013227091633466137,
      "loss": 1.8744,
      "step": 595
    },
    {
      "epoch": 0.3413940256045519,
      "grad_norm": 0.5702312588691711,
      "learning_rate": 0.0001317017643710871,
      "loss": 1.7204,
      "step": 600
    }
  ],
  "logging_steps": 5,
  "max_steps": 1757,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9834119165584384e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
